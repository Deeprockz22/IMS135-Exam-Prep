# ğŸ“Š DAY 1: VISUAL FORMULA CHEAT SHEET
*Mathematical Reference for Quick Lookup*

---

## ğŸ”¢ **CORE VECTOR FORMULAS**

### **Dot Product (Scalar Result)**
```
v Â· w = vâ‚wâ‚ + vâ‚‚wâ‚‚ + vâ‚ƒwâ‚ƒ

Example: [1,2,3] Â· [3,4,5] = 1Ã—3 + 2Ã—4 + 3Ã—5 = 3 + 8 + 15 = 26
```
**Code:** `np.dot(v, w)` or `v @ w`

### **Cross Product (Vector Result, 3D Only)**  
```
v Ã— w = [vâ‚‚wâ‚ƒ - vâ‚ƒwâ‚‚, vâ‚ƒwâ‚ - vâ‚wâ‚ƒ, vâ‚wâ‚‚ - vâ‚‚wâ‚]

Example: [1,2,3] Ã— [3,4,5] = [2Ã—5-3Ã—4, 3Ã—3-1Ã—5, 1Ã—4-2Ã—3] = [-2,4,-2]
```
**Code:** `np.cross(v, w)`

### **Vector Magnitude**
```
||v|| = âˆš(vâ‚Â² + vâ‚‚Â² + vâ‚ƒÂ²)

Example: ||[1,2,3]|| = âˆš(1Â² + 2Â² + 3Â²) = âˆš14 â‰ˆ 3.74
```
**Code:** `np.linalg.norm(v)` or `np.sqrt(v @ v)`

---

## ğŸ”¢ **CORE MATRIX FORMULAS**

### **Matrix-Vector Multiplication**
```
     [a b c]   [x]   [ax + by + cz]
AÃ—v = [d e f] Ã— [y] = [dx + ey + fz]
     [g h i]   [z]   [gx + hy + iz]
```
**Code:** `A @ v`

### **Trace (Sum of Diagonal)**
```
tr(A) = aâ‚â‚ + aâ‚‚â‚‚ + aâ‚ƒâ‚ƒ + ...

Example: tr([[1,2,3],[2,4,5],[3,5,6]]) = 1 + 4 + 6 = 11
```
**Code:** `np.trace(A)`

### **Determinant (2Ã—2 and 3Ã—3)**
```
2Ã—2: det([a b]) = ad - bc
         [c d]

3Ã—3: det(A) = a(ei - fh) - b(di - fg) + c(dh - eg)
```
**Code:** `np.linalg.det(A)`

---

## ğŸ”¢ **EIGENVALUE CONCEPTS**

### **Characteristic Equation**
```
det(A - Î»I) = 0

For 2Ã—2: det([a-Î»  b  ]) = (a-Î»)(d-Î») - bc = 0
            [c   d-Î»]
```

### **Eigenvalue Properties**
```
â€¢ Sum of eigenvalues = trace(A)
â€¢ Product of eigenvalues = det(A)  
â€¢ If Î» is eigenvalue, then Av = Î»v for some vector v
```
**Code:** `la, v = np.linalg.eig(A)`

---

## ğŸ”¢ **EINSTEIN SUMMATION PATTERNS**

### **Common Einstein Notation**
```
Matrix multiplication: C_ik = A_ij B_jk  â†’  'ij,jk->ik'
Double contraction:    s = A_ij B_ij      â†’  'ij,ij->'  
Trace:                tr(A) = A_ii        â†’  'ii->'
Outer product:         C_ij = u_i v_j     â†’  'i,j->ij'
```

### **Einstein Rules**
```
â€¢ Repeated index = sum over it
â€¢ Free index = appears in output  
â€¢ Each index appears exactly twice or is free
```

---

## ğŸ”¢ **NUMERICAL EXAMPLES FOR MEMORIZATION**

### **Standard Test Vectors**
```python
v = [1, 2, 3]     # Easy mental math
w = [3, 4, 5]     # Consecutive numbers

Results to memorize:
v @ v = 14        # 1Â² + 2Â² + 3Â² = 1 + 4 + 9 = 14
v @ w = 26        # 1Ã—3 + 2Ã—4 + 3Ã—5 = 3 + 8 + 15 = 26  
v Ã— w = [-2,4,-2] # Cross product result
```

### **Standard Test Matrix**
```python
A = [[1, 2, 3],
     [2, 4, 5], 
     [3, 5, 6]]

Key results to memorize:
det(A) = -1       # Determinant
tr(A) = 11        # Trace (1 + 4 + 6)
rank(A) = 3       # Full rank
```

---

## ğŸ”¢ **SYSTEM SOLVING COMPARISON**

### **Method Speed Ranking (Fastest â†’ Slowest)**
```
1. np.linalg.solve(A, b)     âš¡ FASTEST - Direct solving
2. Specialized solvers        ğŸš€ Context dependent  
3. np.linalg.inv(A) @ b      ğŸŒ SLOWEST - Avoid in exams!
```

### **When Each Method Fails**
```
solve(A, b):  Fails when A is singular (det(A) = 0)
inv(A):       Fails when A is singular 
pinv(A):      Always works (pseudoinverse)
```

---

## ğŸ”¢ **VISUAL GEOMETRY REMINDERS**

### **Dot Product Geometric Meaning**
```
v Â· w = ||v|| ||w|| cos(Î¸)

Î¸ = 0Â°   â†’ cos(Î¸) = 1  â†’ parallel vectors
Î¸ = 90Â°  â†’ cos(Î¸) = 0  â†’ perpendicular vectors  
Î¸ = 180Â° â†’ cos(Î¸) = -1 â†’ antiparallel vectors
```

### **Cross Product Geometric Meaning**
```
||v Ã— w|| = ||v|| ||w|| sin(Î¸)  (magnitude)
Direction: Right-hand rule (thumb = v, fingers = w, palm = vÃ—w)

Applications:
â€¢ Area of parallelogram = ||v Ã— w||
â€¢ Normal to plane containing v and w
```

---

## ğŸ”¢ **COMMON CALCULATION SHORTCUTS**

### **Powers of Small Integers**
```
1Â² = 1    2Â² = 4     3Â² = 9     4Â² = 16    5Â² = 25
1Â³ = 1    2Â³ = 8     3Â³ = 27    4Â³ = 64    5Â³ = 125
```

### **Square Roots to Remember**
```
âˆš1 = 1    âˆš4 = 2     âˆš9 = 3     âˆš16 = 4    âˆš25 = 5
âˆš14 â‰ˆ 3.74    âˆš26 â‰ˆ 5.10    âˆš50 â‰ˆ 7.07
```

### **Mental Math for Dot Products**
```
[a,b] Â· [c,d] = ac + bd

Quick examples:
[1,2] Â· [3,4] = 1Ã—3 + 2Ã—4 = 3 + 8 = 11
[2,3] Â· [1,4] = 2Ã—1 + 3Ã—4 = 2 + 12 = 14
```

---

## ğŸ”¢ **ERROR CHECKING FORMULAS**

### **Verification Techniques**
```
Matrix multiplication check:
(AB)_ij should equal Î£â‚– A_ik B_kj

Eigenvalue check:  
If Av = Î»v, then ||Av - Î»v|| should be â‰ˆ 0

Orthogonality check:
If v âŸ‚ w, then v Â· w = 0
```

### **Numerical Stability Checks**
```
Condition number: cond(A) = Ïƒ_max / Ïƒ_min
â€¢ cond(A) < 100     â†’ Well conditioned
â€¢ cond(A) > 10â¶     â†’ Poorly conditioned
â€¢ cond(A) = âˆ       â†’ Singular matrix
```

---

## ğŸ¯ **EXAM-SPECIFIC FORMULAS**

### **Most Likely Exam Calculations**
```python
# These appear in 90% of exams:
1. v @ v (vector magnitude squared)
2. A @ v (matrix-vector product) 
3. np.trace(A) (trace calculation)
4. np.linalg.det(A) (determinant)
5. la, n = np.linalg.eig(A) (eigenvalues)
6. np.einsum('ij,ij', A, B) (double contraction)
```

### **Problem Types to Expect**
```
Type 1: Given vectors, compute dot/cross products
Type 2: Given matrix, find eigenvalues/trace/determinant
Type 3: Solve linear system Ax = b
Type 4: Use Einstein notation for tensor operations
Type 5: Analyze linear independence of vectors
```

---

## ğŸ“± **MOBILE-FRIENDLY SUMMARY**

**Essential Memory List:**
```
â€¢ Four dot products: @, dot, inner, einsum
â€¢ Matrix ops: .T, trace, det, rank
â€¢ Eigenvalues FIRST: la, n = eig(A)  
â€¢ Solve don't invert: solve(A,b) not inv(A)@b
â€¢ Cross 3D only: np.cross needs 3D vectors
â€¢ Einstein: repeat=sum, free=output
```

**Speed Calculations:**
```
[1,2,3] @ [1,2,3] = 14
[1,2,3] @ [3,4,5] = 26  
[[1,2,3],[2,4,5],[3,5,6]] â†’ det=-1, tr=11
```

---

*Perfect for phone screenshots! Keep this handy during commute study.*