{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info\n",
    "\n",
    "Aids: python help file \"python_help_230924.ipynb\"\n",
    "\n",
    "You can hand in hand-written answers (or part of answers). These will be collected after the exam. On the envelope of the hand-written papers write your computer name. \n",
    "\n",
    "Comment your code in your files (.ipynb or .py) to explain your solutions/answers. Save these codes/files under c:\\__exam__\\Assignments\\\n",
    "\n",
    "On the top of each file write your anonymous code e.g. #ims135-123456\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "max point= 27p\n",
    "\n",
    "grade 5: 22-27p (80-100%)\n",
    "\n",
    "grade 4: 16-21p (60-80%)\n",
    "\n",
    "grade 3: 11-15 (40-60%)\n",
    "\n",
    "\n",
    "(the exact number of max points can differ between different exams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful packages (from python help file)\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import math as mt\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams # for changing default values\n",
    "import scipy.io as sio\n",
    "import scipy.optimize\n",
    "from scipy.optimize import minimize\n",
    "import timeit\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (3p)\n",
    "\n",
    "Explain the fundamental differences between regression, classification, and clustering in machine learning. Provide examples of  applications for each of these tasks and tell whether they belong to supervised or unsupervised learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (5p)\n",
    "\n",
    "Assume that you have obtained experimental data in the form of snapshots of 20 displacements at 400 time instances. The data is stored in the matrix X, which you can find in the file bar_result.mat . The displacements are measured in millimeters (mm) and are recorded at 20 locations between $x=0$ m to $x=1$ m. The time instances are recorded between $t=0$ s to $t=0.4$ s.\n",
    "\n",
    "a) Calculate the singular values of the matrix $X$ and give the 4 largest.\n",
    "\n",
    "b) Use SVD to approximate the data matrix X by retaining only the top 3 singular values. Determine the L2 norm of the error between  the approximated $X$ and the original $X$, and also, calculate how many numerical values need to be stored for this approximation compared to for the full $X$.\n",
    "\n",
    "c) Generate plots to visualize the spatial and temporal patterns for the three terms retained in the SVD approximation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from .mat file, example\n",
    "mat_file=sio.loadmat('bar_result.mat')\n",
    "X=mat_file['X'] # Experimental data: x and time coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (3p)\n",
    "Find the values of $x_1$ and $x_2$ that minimize the function $f(x_1,x_2)=(x_2-1)^2-(x_2-1) \\cdot ( (x_1+1)^2+(x_2-1)^2)+( (x_1+1)^2+(x_2-1)^2)^2$. For this optimization task, use the PyTorch implementations of the optimization algorithms stochastic gradient descent (torch.optim.SGD) and LBFGS. Use the initial guess $x_1=x_2=0$. Perform the optimization with two different learning rates: 0.1 and 1.  Discuss the results obtained for both algorithms with the varying learning rates and elaborate on the significance of the choice of learning rate in optimization problems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (3p)\n",
    "Cross-validation is a critical step in machine learning model development. Explain how such a procedure can be conducted and disuss why it is essential to perform a cross-validation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (3p)\n",
    "For the NN in the figure:\n",
    "![simple nn from Fig 3.5 in Kollmannsberger et al](fig/simple_nn.png \"MarineGEO logo\")  \n",
    "Assume $w_{11}^{(1)}=1$, $w_{12}^{(1)}=-3$, $w_{21}^{(1)}=-2$, $w_{22}^{(1)}=1$, $w_{1}^{(2)}=2$, $w_{2}^{(2)}=-1$ and that the activation functions are the tanh. Determine the gradients of the weights (=parameters of the NN) on the the output $\\hat{y}$ for $x=[3,2]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (5p)\n",
    "\n",
    "Measurements of beam deflections have been conducted (for the same material and loading). Five different beams with with the following lengths and quadratic cross-section widths have been tested. \n",
    "\n",
    "$L=1, \\, 1, \\, 3, \\, 5, \\, 7 $\n",
    "\n",
    "$b=1, \\, 2, \\, 1, \\, 2, \\, 3 $\n",
    "\n",
    "The measurements gave the deflections: \n",
    "\n",
    "$4.1, \\, 0.25, \\, 107, \\, 31, \\, 17$\n",
    "\n",
    "a) Try to fit a NN to the experimental data. Assume 2 hidden layers with 10 neurons in both these layers. Apply the sigmoid activation function. Compute the output for the trained NN for the measurements.\n",
    "\n",
    "b) An additional experiment has been conducted. The displacement was measured to $31.2$ for the length $5$ and quadratic cross-section width $2$. Compute the results from your trained NN.\n",
    "\n",
    "\n",
    "Note, that the all measurement results, lengths and widths have been made dimensionless. Furthermore, you can use any regularization parameter and optimization algorithm (with tolerances etc.) that works for you.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=torch.tensor([[1.,1.],[1.,2.],[3.,1.],[5.,2.],[7.,3.]],dtype=torch.float32) #input torch.tensor to your NN for the experiments\n",
    "target_data=torch.tensor([[4.1],[0.25],[107.],[31],[17]],dtype=torch.float32)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (5p)\n",
    "\n",
    "The conservation of mass for an axisymmetric plane flow problem can be written as\n",
    "\n",
    "$$\n",
    "\\frac{d u}{d r}+C \\, \\frac{u}{r}=0\n",
    "$$\n",
    "where $C=1$. Now this equation is extended by allowing $C$ to vary with $r$. Determine $C(r)$ and $u(r)$ by using PINN. Compare the obtained $u(r)$ with the measurement points (see below). Apply a NN with one hidden layer, 20 neurons and the activation function $tanh$.\n",
    "\n",
    "The measurement points of $u$ at different $r$ values can be (for simplicity) obtained from the following code snippet: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "L = 1\n",
    "a=2.\n",
    "\n",
    "def generate_grid_1d(length, samples=20, initial_coordinate=L):\n",
    "    \"\"\"Generate an evenly space grid of a given length and a given number of samples.\"\"\"\n",
    "\n",
    "    # Generate the grid\n",
    "    x = torch.linspace(initial_coordinate, initial_coordinate + length, samples, requires_grad=True)\n",
    "\n",
    "    # Reshape on a column tensor and return\n",
    "    return x.view(samples, 1)\n",
    "\n",
    "#grid points\n",
    "r = generate_grid_1d(a, N)\n",
    "\n",
    "#'measurements'\n",
    "ua=3.\n",
    "u_measurements=ua*a/r*torch.exp(0.1*(a-r))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
